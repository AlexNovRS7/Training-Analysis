{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    url = 'https://www.strava.com/oauth/token',\n",
    "    data = {'client_id':\"61279\",\n",
    "            'client_secret':\"9859ded508278dfbcf717854a3636bdb396ed6bb\",\n",
    "            'code':'44124449ece3078e72ad145d703fcd59682260af',\n",
    "            'grant_type':'authorization_code'})\n",
    "\n",
    "json_response = json.loads(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFRESH_TOKEN = json_response[\"refresh_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    url = 'https://www.strava.com/oauth/token',\n",
    "    data = {'client_id':\"61279\",\n",
    "            'client_secret':\"9859ded508278dfbcf717854a3636bdb396ed6bb\",\n",
    "            'refresh_token':REFRESH_TOKEN,\n",
    "            'grant_type':'refresh_token'})\n",
    "json_response = json.loads(response.text)\n",
    "try:\n",
    "    REFRESH_TOKEN = json_response[\"refresh_token\"]\n",
    "    ACCESS_TOKEN = json_response[\"access_token\"]\n",
    "except:\n",
    "    print(\"Something is wrong, go get new code again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "activities_response = session.get(f\"https://www.strava.com/api/v3/athlete/activities?type=Ride&access_token={ACCESS_TOKEN}&=per_page=3000\") \n",
    "json_response = json.loads(activities_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in json_response:\n",
    "    if tr[\"type\"] != \"WeightTraining\":\n",
    "        print(tr)\n",
    "        id = tr[\"id\"]\n",
    "\n",
    "        stream_response = session.get(f\"https://www.strava.com/api/v3/activities/{id}/streams/watts?access_token={ACCESS_TOKEN}\") \n",
    "        stream_json = json.loads(stream_response.text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_response = session.get(f\"https://www.strava.com/api/v3/activities/10174746579/streams/watts?access_token={ACCESS_TOKEN}\") \n",
    "stream_json = json.loads(stream_response.text)\n",
    "stream_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stream_response:\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_stream(activity_id):\n",
    "    print(f\"Downloading power for {activity_id}\")\n",
    "    while True:\n",
    "        stream_response = session.get(f\"https://www.strava.com/api/v3/activities/{activity_id}/streams/watts?access_token={ACCESS_TOKEN}\") \n",
    "        print(f\"Sent get request for {activity_id}\")\n",
    "        stream_json = json.loads(stream_response.text)\n",
    "        for stream in stream_json:\n",
    "            try:\n",
    "                if stream[\"type\"] == \"watts\":\n",
    "                    return stream[\"data\"]\n",
    "                else:\n",
    "                    break\n",
    "            except TypeError:\n",
    "                print(\"Rate limit exceeded, waiting for 7 minutes\")\n",
    "                print(stream_json)\n",
    "                time.sleep(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_cycling_activities(access_token, after):\n",
    "    base_url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "    page = 1\n",
    "    per_page = 30  # Adjust as needed\n",
    "\n",
    "    all_activities = []\n",
    "\n",
    "    while True:\n",
    "        params = {\"type\": \"Ride\", \"page\": page, \"per_page\": per_page, \"after\": after}\n",
    "        headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "\n",
    "        response = requests.get(base_url, params=params, headers=headers)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        activities = response.json()\n",
    "\n",
    "        # Process the activities here, e.g., store them in a list\n",
    "        all_activities.extend(activities)\n",
    "\n",
    "        # Check if there are more pages\n",
    "        if len(activities) < per_page:\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return all_activities\n",
    "\n",
    "#all_cycling_activities = get_all_cycling_activities(ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, filename):\n",
    "    if not data:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    \n",
    "    # Extract all unique keys from all activities\n",
    "    fields = set().union(*(d.keys() for d in data))\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write the data\n",
    "        writer.writerows(data)\n",
    "        \n",
    "save_to_csv(all_cycling_activities, 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(all_cycling_activities)\n",
    "df = df.loc[(df[\"type\"].str.contains(\"Ride\"))]\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"])\n",
    "df[\"start_date\"] = df[\"start_date\"].dt.tz_localize(None).dt.date\n",
    "df.sort_values(\"start_date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_df = pd.read_csv('ATP - FTP.csv')\n",
    "ftp_df[\"Date\"] = pd.to_datetime(ftp_df[\"Date\"], format=\"%d/%m/%Y\").dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(ftp_df[[\"Date\", \"Power\"]], how='left', left_on='start_date', right_on='Date')\n",
    "df[\"FTP set\"] = df[\"Power\"].ffill()\n",
    "df.drop([\"Date\", \"Power\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('activities.json') as activities_file:\n",
    "    parsed_json = json.load(activities_file)\n",
    "\n",
    "last_epoch = 0\n",
    "for activity in all_cycling_activities[:10]:\n",
    "    print(parser.parse(activity[\"start_date\"]).timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('activities.json') as activities_file:\n",
    "    all_cycling_activities = json.load(activities_file)\n",
    "print(f\"Opened {len(all_cycling_activities)} existing activities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_epoch = max([parser.parse(activity[\"start_date\"]).timestamp() for activity in all_cycling_activities])\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "print(f\"Requesting activities after epoch {last_epoch}\")\n",
    "new_cycling_activities = get_all_cycling_activities(ACCESS_TOKEN, last_epoch)\n",
    "print(f\"Downloaded {len(new_cycling_activities)} new activities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cycling_activities.extend(new_cycling_activities)\n",
    "print(f\"Stacked both files. Activities in sum {len(all_cycling_activities)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(all_cycling_activities)\n",
    "for i, activity in enumerate(all_cycling_activities):\n",
    "    if \"Ride\" in activity[\"type\"] and activity.get(\"device_watts\", False):\n",
    "        value = activity.get(\"power_stream\", None)\n",
    "        if value is None:\n",
    "            activity[\"power_stream\"] = get_power_stream(activity[\"id\"])\n",
    "            print(f\"{i}/{n} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for activity in all_cycling_activities:\n",
    "    if \"Ride\" in activity[\"type\"]:\n",
    "        value = activity.get(\"power_stream\", None)\n",
    "        if value is not None:\n",
    "            i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('activities.json', 'w') as activities_file:\n",
    "    json.dump(all_cycling_activities, activities_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_cycling_activities)\n",
    "df = df.loc[(df[\"type\"].str.contains(\"Ride\"))]\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"])\n",
    "df[\"start_date\"] = df[\"start_date\"].dt.tz_localize(None).dt.date\n",
    "df.sort_values(\"start_date\", inplace=True)\n",
    "\n",
    "ftp_df = pd.read_csv('ATP - FTP.csv')\n",
    "ftp_df[\"Date\"] = pd.to_datetime(ftp_df[\"Date\"], format=\"%d/%m/%Y\").dt.date\n",
    "print(\"FTP file loaded\")\n",
    "\n",
    "df = df.merge(ftp_df[[\"Date\", \"Power\"]], how='left', left_on='start_date', right_on='Date')\n",
    "df[\"FTP set\"] = df[\"Power\"].ffill()\n",
    "df.drop([\"Date\", \"Power\"], axis=1, inplace=True)\n",
    "print(\"Activities and FTP dataframes merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_np(power_stream):\n",
    "    if power_stream is not np.nan:\n",
    "        watts_df = pd.DataFrame(power_stream, columns=[\"Wats\"])\n",
    "        watts_df[\"30s rolling w\"] = watts_df[\"Wats\"].rolling(30, 0).mean() ** 4\n",
    "\n",
    "        avg_powered_values = watts_df[\"30s rolling w\"].mean()\n",
    "        return avg_powered_values ** 0.25\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df[\"NP\"] = df[\"power_stream\"].apply(lambda x: calculate_np(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cycling_activities.csv\")\n",
    "df = df[df[\"device_watts\"]==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"])\n",
    "df[\"start_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr =pd.date_range(df[\"start_date\"].min(), datetime.datetime.today().date(), freq='D')\n",
    "dtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(\"start_date\").sum()\n",
    "df = df.reindex(dtr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('activities.json') as activities_file:\n",
    "    all_cycling_activities = json.load(activities_file)\n",
    "\n",
    "df = pd.DataFrame(all_cycling_activities)\n",
    "df = df.loc[(df[\"type\"].str.contains(\"Ride\")) & (df[\"device_watts\"]==True)]\n",
    "df[\"start_date\"] = pd.to_datetime(df[\"start_date\"])\n",
    "df[\"start_date\"] = df[\"start_date\"].dt.tz_localize(None).dt.date\n",
    "df.sort_values(\"start_date\", inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftp_df = pd.read_csv('ATP - FTP.csv')\n",
    "ftp_df[\"Date\"] = pd.to_datetime(ftp_df[\"Date\"], format=\"%d/%m/%Y\").dt.date\n",
    "print(\"FTP file loaded\")\n",
    "\n",
    "df = df.merge(ftp_df[[\"Date\", \"Power\"]], how='left', left_on='start_date', right_on='Date')\n",
    "df[\"FTP set\"] = df[\"Power\"].ffill()\n",
    "df.drop([\"Date\", \"Power\"], axis=1, inplace=True)\n",
    "print(\"Activities and FTP dataframes merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NP\"] = df[\"power_stream\"].apply(lambda x: calculate_np(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"IF\"] = df[\"NP\"]/df[\"FTP set\"]\n",
    "print(\"IF calculated\")\n",
    "\n",
    "df[\"TSS\"] = ((df[\"moving_time\"] * df[\"NP\"] * df[\"IF\"]) / (df[\"FTP set\"]*3600)) * 100\n",
    "print(\"TSS calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(\"start_date\")[\"TSS\"].sum()\n",
    "df = df.reindex(dtr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TSS\"].fillna(0, inplace=True)\n",
    "df[\"CTL\"] = df[\"TSS\"].rolling(42,0).mean().shift(1)\n",
    "print(\"CTL calculated\")\n",
    "\n",
    "df[\"ATL\"] = df[\"TSS\"].rolling(7,0).mean().shift(1)\n",
    "print(\"ATL calculated\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('CTL_ATL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# garmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import garminconnect\n",
    "from getpass import getpass\n",
    "\n",
    "email = \"Sashko0002@gmail.com\"\n",
    "password = \"Sanches19980606\"\n",
    "\n",
    "garmin = garminconnect.Garmin(email, password)\n",
    "garmin.login()\n",
    "\n",
    "garmin.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "GARTH_HOME = os.getenv(\"GARTH_HOME\", \"~/.garth\")\n",
    "garmin.garth.dump(GARTH_HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "yesterday = date.today() - timedelta(days=1)\n",
    "yesterday = yesterday.isoformat()\n",
    "garmin.get_stats(yesterday).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garmin.get_sleep_data('2023-12-28').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garmin.get_sleep_data('2023-12-29')['dailySleepDTO']['sleepScores']['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30, 1, -1):\n",
    "    dt = (date.today() - timedelta(days=i)).isoformat()\n",
    "    print(dt)\n",
    "\n",
    "    try:\n",
    "        sleep_score = garmin.get_sleep_data(dt)['dailySleepDTO']['sleepScores']['overall']['value']\n",
    "    except KeyError:\n",
    "        sleep_score = \"\"\n",
    "        \n",
    "    print(sleep_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garmin_activities = garmin.get_activities_by_date(\"2022-09-01\", date.today().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(garmin_activities).to_csv('garmin_activities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(garmin_activities)\n",
    "df[\"activityType\"] = df['activityType'].apply(lambda x: x['typeKey'])\n",
    "\n",
    "df[\"activityType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    df[\"activityType\"].isin([\"road_biking\", \"virtual_ride\", \"cycling\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"power/hr\"] = df['avgPower']/df['averageHR']\n",
    "df[\"month\"] = pd.to_datetime(df[\"startTimeLocal\"]).dt.strftime(\"%Y-%m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df[\"month\"])[\"power/hr\"].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_data = garmin.get_heart_rates(\"2023-12-28\")[\"heartRateValues\"]\n",
    "hr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_zones(x):\n",
    "    try:\n",
    "        if x <= 60:\n",
    "            return 0\n",
    "        elif x <= 80:\n",
    "            return 1\n",
    "        elif x <= 100:\n",
    "            return 3\n",
    "        elif x <= 120:\n",
    "            return 4\n",
    "        elif x <= 140:\n",
    "            return 5\n",
    "        elif x <= 160:\n",
    "            return 6\n",
    "        elif x <= 180:\n",
    "            return 7\n",
    "        else:\n",
    "            return 8\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "zones = [map_zones(value) for value in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "timestamps, values = zip(*hr_data)\n",
    "dates = [datetime.datetime.utcfromtimestamp(ts / 1000) for ts in timestamps]\n",
    "mapped_zones  = [map_zones(value) for value in values]\n",
    "\n",
    "# Create a DataFrame with mapped zones\n",
    "df = pd.DataFrame({'Value': mapped_zones})\n",
    "\n",
    "# Count occurrences of each zone\n",
    "zone_counts = df['Value'].value_counts().sort_index().reset_index()\n",
    "zone_counts.columns = ['Zone', 'Count']\n",
    "\n",
    "# Calculate percentages\n",
    "zone_counts['Percentage'] = zone_counts['Count'] / zone_counts['Count'].sum() * 100\n",
    "\n",
    "# Plotting histogram with hover information\n",
    "fig = px.bar(zone_counts, x='Zone', y='Count', text='Percentage',\n",
    "             title='Histogram of Mapped Zones with Percentage Information',\n",
    "             labels={'Zone': 'Zone', 'Count': 'Number of Entries'},\n",
    "             hover_data={'Percentage': ':.2f%'})\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(garmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
